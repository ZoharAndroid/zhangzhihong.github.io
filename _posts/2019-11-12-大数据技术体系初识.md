---
layout: post
title: 大数据技术体系初识
tags: [大数据]
categories: [大数据]
---

<!-- TOC -->

- [1. 数据收集](#1-%e6%95%b0%e6%8d%ae%e6%94%b6%e9%9b%86)
  - [1.1. Sqoop](#11-sqoop)
  - [1.2. Flume](#12-flume)
  - [1.3. Kafka分布式消息队列](#13-kafka%e5%88%86%e5%b8%83%e5%bc%8f%e6%b6%88%e6%81%af%e9%98%9f%e5%88%97)
    - [1.3.1. Kafka各个组件](#131-kafka%e5%90%84%e4%b8%aa%e7%bb%84%e4%bb%b6)

<!-- /TOC -->

# 1. 数据收集

## 1.1. Sqoop

Sqoop是为了就解决关系数据库与Hadoop之间数据传输问题，构建了这两者之间的“桥梁”。

![image](http://tc-test.nos-eastchina1.126.net/2019-11/12/16-48-33-871.jpg)

Sqoop采用Connecter架构，主要负责从特定数据源中抽取和加载数据。

Sqoop主要具备以下特点：
1. 性能高：Sqoop采用MapReduce完成数据的导入和导出，具有MapReduce的并发度可控、容错性高、扩展性高等优点；
2. 自动类型转换：Sqoop可读取数据元信息，自动完成数据类型映射，也可自定义类型映射关系；
3. 自动传播元信息：Sqoop在发送端和接收端传递数据的同时，也会将元信息传递过去，保证接收端和发送端有一致的元信息。

## 1.2. Flume

如何高效收集各种各样的日志，并发送到后端存储系统（比如Hadoop、数据仓库等）中进行统一分析和挖掘，是每个公司需要解决的问题。

![image](http://tc-test.nos-eastchina1.126.net/2019-11/12/22-19-53-967.jpg)

日志收集面临的问题：
1. **数据源种类多**：各种服务均会产生日志，格式也不通过，产生的日志方式也不同；
2. **数据源是物理分布的**：各种服务运行在不同的机器上，有的甚至跨机房的；
3. **流式的不间断产生**：日志实时产生，需要实时收集便于后端的分析和挖掘。

> Flume系统是解决以上流式数据收集问题的，是一个通过用的六十数据收集系统，可以将不同的数据源产生的流式数据接近实时的发送到后端中心化的存储系统中，具有分布式、良好的可靠性和可用性等优点。

Flume系统的特点：
1. **良好的扩展性**：Flume架构是完全分布式的，容易扩展；
2. **高度定制化**：各个组件是可插拔的，可根据需求进行定制；
3. **声明式动态化配置**：可根据需求动态配置基于Flume的数据流拓扑结构。
4. **内置支持事务**。

Flume的数据流是通过一系列Agent组件构成的。

![](https://raw.githubusercontent.com/ZoharAndroid/MarkdownImages/master/2019-11/Flume%E5%9F%BA%E6%9C%AC%E6%9E%84%E6%88%90.png)

Agent内部三个组件：Souce、Channel、Sink。

![](https://raw.githubusercontent.com/ZoharAndroid/MarkdownImages/master/2019-11/FlumeAgent%E5%9F%BA%E6%9C%AC%E6%9E%84%E6%88%90.png)

## 1.3. Kafka分布式消息队列

Kafka架构有Producer、Broker和Consumer组件构成，其中Producer将数据写入Broker，Consumer从Broker上读取数据进行处理，Broker构成了链接Producer和Comsumer的“缓冲区”。Borker和Comsumer通过Zookeeper协调和服务发现。

![Kafka基本架构]()

Kafka采用了顺序读写和批量写机制。Kafka将数据分区保存，并将每个分区保存成多份以提高数据可靠性。

### 1.3.1. Kafka各个组件

1. Producer

将数据转化成“消息”，并通过网络发送给Broker。

2. Broker

接受Producer和Consumer的请求，把消息持久化到本地磁盘。


