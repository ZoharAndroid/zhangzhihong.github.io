---
layout: post
title: 大数据学习10--ssh免密登录和群起集群
tags: [大数据]
categories: 大数据
---

为什么要用SSH免密登录呢？这个是为了提供方便，一个集群肯定会有很多节点，作为一个开发者，虽然可以一个一个的去开启每个节点，但是这样费时费力的事情，尽量还是少做吧，所以出现了这篇博客。用ssh免密登录来群起节点。

下面来看下如何进行配置的。



# 生成公钥和私钥

```
[zohar@hadoop102 ~]$ ssh-keygen -t rsa
Generating public/private rsa key pair.
Enter file in which to save the key (/home/zohar/.ssh/id_rsa): 
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in /home/zohar/.ssh/id_rsa.
Your public key has been saved in /home/zohar/.ssh/id_rsa.pub.
The key fingerprint is:
6d:38:65:6f:24:5e:b1:5e:03:6a:3e:27:17:6c:e2:4a zohar@hadoop102
The key's randomart image is:
+--[ RSA 2048]----+
|            o    |
|           o +   |
|          B B o  |
|         X O o . |
|        E O *    |
|       . + *     |
|        .        |
|                 |
|                 |
+-----------------+
```

可以进去文档进行查看：.pub就是公钥，id_rsa就是私钥。
```
[zohar@hadoop102 ~]$ cd .ssh/
[zohar@hadoop102 .ssh]$ ll
总用量 12
-rw-------. 1 zohar zohar 1675 12月 12 10:14 id_rsa
-rw-r--r--. 1 zohar zohar  397 12月 12 10:14 id_rsa.pub
-rw-r--r--. 1 zohar zohar 1215 12月 11 08:51 known_hosts
```

# 将公钥拷贝到需要免密登录的机器上

```
[zohar@hadoop102 ~]$ ssh-copy-id hadoop102
[zohar@hadoop102 ~]$ cd ..
[zohar@hadoop102 ~]$ xsync .ssh/
```
> 这里为了简便操作，hadoop102 生成了自己的公钥，然后通过xsync工具把`.ssh`分别传递到hadoop102、hadoop103、hadoop104机器上，这样就可以相互之间免密操作了。

在102机器上可以测试一下：
```
[zohar@hadoop102 ~]$ ssh hadoop103
Last login: Thu Dec 12 14:08:30 2019 from hadoop102
[zohar@hadoop103 ~]$ ssh hadoop104
Last login: Thu Dec 12 14:08:39 2019 from hadoop102
[zohar@hadoop104 ~]$ 
```
> 可以看到，不用属于密码就可以访问103，104机器了。

# 群起集群

## 配置slaves

```
[root@hadoop102 hadoop-2.10.0]# vim etc/hadoop/slaves 
```

把子节点填入：
```
hadoop102
hadoop103
hadoop104
```

## 集群全部同步

```
[root@hadoop102 hadoop-2.10.0]# xsync etc/
```

## 启动集群

```
[root@hadoop102 hadoop-2.10.0]# start-dfs.sh 
```

## 启动yarn

在103机器上启动yarn
```
[root@hadoop103 hadoop-2.10.0]# sbin/start-yarn.sh 
starting yarn daemons
starting resourcemanager, logging to /opt/module/hadoop-2.10.0/logs/yarn-root-resourcemanager-hadoop103.out
hadoop103: starting nodemanager, logging to /opt/module/hadoop-2.10.0/logs/yarn-root-nodemanager-hadoop103.out
hadoop104: starting nodemanager, logging to /opt/module/hadoop-2.10.0/logs/yarn-root-nodemanager-hadoop104.out
hadoop102: starting nodemanager, logging to /opt/module/hadoop-2.10.0/logs/yarn-root-nodemanager-hadoop102.out
```

## 浏览器查看secondarynamenode

```
http://hadoop104:50090/status.html
```

# 集群测试

## 上传文件到集群

```
[root@hadoop102 hadoop-2.10.0]# hadoop fs -put wcinput /
```

## 运行mapreduce
```
[root@hadoop102 hadoop-2.10.0]# hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.0.jar wordcount /wcinput /output
```

## 查看运行结果

```
[root@hadoop102 hadoop-2.10.0]# hadoop fs -cat /output/*
19/12/12 16:07:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
a	2
hadoop	1
haha	1
helloworld	1
this	1
zhangzhihong	2
```

在浏览器上也可以查看
```
http://hadoop102:50070/explorer.html#/
```

![](https://gitee.com/zhangzh_cs/md_image/raw/76c6f5a46188372551551ce3d7c741a24cab8b1c/2019-12/mapreduce%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C.png)





